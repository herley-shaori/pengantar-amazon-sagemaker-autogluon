{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "!{sys.executable} -m pip install -U pip sagemaker-studio-image-build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train.py\n",
    "import os\n",
    "import json\n",
    "import boto3\n",
    "import json\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "prefix = \"/opt/ml\"\n",
    "input_path = os.path.join(prefix, \"input/data\")\n",
    "output_path = os.path.join(prefix, \"output\")\n",
    "model_path = os.path.join(prefix, \"model\")\n",
    "param_path = os.path.join(prefix, 'input/config/hyperparameters.json')\n",
    "\n",
    "\n",
    "def train(params):\n",
    "    label = params[\"label\"]\n",
    "    channel_name = \"training\"\n",
    "    training_path = os.path.join(input_path, channel_name)\n",
    "    training_dataset = TabularDataset(os.path.join(training_path, \"training.csv\"))\n",
    "    predictor = TabularPredictor(label=label, path=model_path).fit(training_dataset)\n",
    "    with open(os.path.join(model_path, \"Fit_Summary.txt\"), \"w\") as f:\n",
    "        print(predictor.fit_summary(), file=f)\n",
    "    return predictor\n",
    "    \n",
    "\n",
    "def test(params, predictor):\n",
    "    label = params[\"label\"]\n",
    "    channel_name = \"testing\"\n",
    "    testing_path = os.path.join(input_path, channel_name)\n",
    "    testing_dataset = TabularDataset(os.path.join(testing_path, \"testing.csv\"))\n",
    "    ground_truth = testing_dataset[label]\n",
    "    testing_data = testing_dataset.drop(columns=label)\n",
    "    predictions = predictor.predict(testing_data)\n",
    "    with open(os.path.join(model_path, \"Model_Evaluation.txt\"), \"w\") as f:\n",
    "        print(\n",
    "            json.dumps(\n",
    "                predictor.evaluate_predictions(\n",
    "                    y_true=ground_truth,\n",
    "                    y_pred=predictions,\n",
    "                    auxiliary_metrics=True\n",
    "                ),\n",
    "                indent=4\n",
    "            ),\n",
    "            file=f\n",
    "        )\n",
    "    leaderboard = predictor.leaderboard(testing_dataset, silent=True)\n",
    "    leaderboard.to_csv(os.path.join(model_path, \"Leaderboard.csv\"))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Loading Parameters\\n\")\n",
    "    with open(param_path) as f:\n",
    "        params = json.load(f)\n",
    "    print(\"Training Models\\n\")\n",
    "    predictor = train(params)\n",
    "    print(\"Testing Models\\n\")\n",
    "    test(params, predictor)\n",
    "    print(\"AutoGluon Job Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dockerfile\n",
    "ARG REGION\n",
    "FROM 763104351884.dkr.ecr.${REGION}.amazonaws.com/autogluon-training:0.3.1-cpu-py37-ubuntu18.04\n",
    "RUN pip install -U pip\n",
    "RUN pip install bokeh==2.0.1\n",
    "RUN mkdir -p /opt/program\n",
    "RUN mkdir -p /opt/ml\n",
    "COPY train.py /opt/program\n",
    "WORKDIR /opt/program\n",
    "ENTRYPOINT [\"python\", \"train.py\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...[Container] 2023/01/08 06:32:09 going inside waitForAgent\n",
      "\n",
      "[Container] 2023/01/08 06:32:09 Waiting for agent ping\n",
      "[Container] 2023/01/08 06:32:10 Waiting for DOWNLOAD_SOURCE\n",
      "[Container] 2023/01/08 06:32:12 Phase is DOWNLOAD_SOURCE\n",
      "[Container] 2023/01/08 06:32:12 finished waitForAgent\n",
      "[Container] 2023/01/08 06:32:12 CODEBUILD_SRC_DIR=/codebuild/output/src503828207/src\n",
      "[Container] 2023/01/08 06:32:12 YAML location is /codebuild/output/src503828207/src/buildspec.yml\n",
      "[Container] 2023/01/08 06:32:12 Setting HTTP client timeout to higher timeout for S3 source\n",
      "[Container] 2023/01/08 06:32:12 Processing environment variables\n",
      "[Container] 2023/01/08 06:32:12 No runtime version selected in buildspec.\n",
      "[Container] 2023/01/08 06:32:13 Moving to directory /codebuild/output/src503828207/src\n",
      "[Container] 2023/01/08 06:32:13 Configuring ssm agent with target id: codebuild:f458e01c-f72c-4b93-a33b-f40a0af8f23c\n",
      "[Container] 2023/01/08 06:32:13 Successfully updated ssm agent configuration\n",
      "[Container] 2023/01/08 06:32:13 Registering with agent\n",
      "[Container] 2023/01/08 06:32:13 Phases found in YAML: 3\n",
      "[Container] 2023/01/08 06:32:13  POST_BUILD: 3 commands\n",
      "[Container] 2023/01/08 06:32:13  PRE_BUILD: 9 commands\n",
      "[Container] 2023/01/08 06:32:13  BUILD: 4 commands\n",
      "[Container] 2023/01/08 06:32:13 Phase complete: DOWNLOAD_SOURCE State: SUCCEEDED\n",
      "[Container] 2023/01/08 06:32:13 Phase context status code:  Message:\n",
      "[Container] 2023/01/08 06:32:13 Entering execCommands\n",
      "[Container] 2023/01/08 06:32:13 Entering phase INSTALL\n",
      "[Container] 2023/01/08 06:32:13 Phase complete: INSTALL State: SUCCEEDED\n",
      "[Container] 2023/01/08 06:32:13 Phase context status code:  Message:\n",
      "[Container] 2023/01/08 06:32:13 Entering phase PRE_BUILD\n",
      "[Container] 2023/01/08 06:32:13 Running command echo Logging in to Amazon ECR...\n",
      "Logging in to Amazon ECR...\n",
      "\n",
      "[Container] 2023/01/08 06:32:13 Running command $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION)\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /root/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "[Container] 2023/01/08 06:32:27 Running command $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION --registry-ids 763104351884)\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /root/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "[Container] 2023/01/08 06:32:28 Running command $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION --registry-ids 217643126080)\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /root/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "[Container] 2023/01/08 06:32:28 Running command $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION --registry-ids 727897471807)\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /root/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "[Container] 2023/01/08 06:32:29 Running command $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION --registry-ids 626614931356)\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /root/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "[Container] 2023/01/08 06:32:29 Running command $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION --registry-ids 683313688378)\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /root/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "[Container] 2023/01/08 06:32:30 Running command $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION --registry-ids 520713654638)\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /root/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "[Container] 2023/01/08 06:32:30 Running command $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION --registry-ids 462105765813)\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /root/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "[Container] 2023/01/08 06:32:31 Phase complete: PRE_BUILD State: SUCCEEDED\n",
      "[Container] 2023/01/08 06:32:31 Phase context status code:  Message:\n",
      "[Container] 2023/01/08 06:32:31 Entering phase BUILD\n",
      "[Container] 2023/01/08 06:32:31 Running command echo Build started on `date`\n",
      "Build started on Sun Jan 8 06:32:31 UTC 2023\n",
      "\n",
      "[Container] 2023/01/08 06:32:31 Running command echo Building the Docker image...\n",
      "Building the Docker image...\n",
      "\n",
      "[Container] 2023/01/08 06:32:31 Running command docker build -t $IMAGE_REPO_NAME:$IMAGE_TAG --build-arg REGION=ap-southeast-1 .\n",
      "Sending build context to Docker daemon   42.5kB\n",
      "Step 1/9 : ARG REGION\n",
      "Step 2/9 : FROM 763104351884.dkr.ecr.${REGION}.amazonaws.com/autogluon-training:0.3.1-cpu-py37-ubuntu18.04\n",
      "0.3.1-cpu-py37-ubuntu18.04: Pulling from autogluon-training\n",
      "e4ca327ec0e7: Pulling fs layer\n",
      "3b911466f23c: Pulling fs layer\n",
      "88617b1e05df: Pulling fs layer\n",
      "d8988db501a0: Pulling fs layer\n",
      "246ae1b20320: Pulling fs layer\n",
      "1858d192a56c: Pulling fs layer\n",
      "88b8cc84069a: Pulling fs layer\n",
      "d9fac7b97446: Pulling fs layer\n",
      "953ce81694d3: Pulling fs layer\n",
      "c34d068d8571: Pulling fs layer\n",
      "07a6a041312d: Pulling fs layer\n",
      "6efc8cdc3722: Pulling fs layer\n",
      "78fc2e423513: Pulling fs layer\n",
      "d8988db501a0: Waiting\n",
      "246ae1b20320: Waiting\n",
      "1858d192a56c: Waiting\n",
      "88b8cc84069a: Waiting\n",
      "d9fac7b97446: Waiting\n",
      "953ce81694d3: Waiting\n",
      "c34d068d8571: Waiting\n",
      "07a6a041312d: Waiting\n",
      "6efc8cdc3722: Waiting\n",
      "78fc2e423513: Waiting\n",
      "88617b1e05df: Verifying Checksum\n",
      "88617b1e05df: Download complete\n",
      "d8988db501a0: Verifying Checksum\n",
      "d8988db501a0: Download complete\n",
      "246ae1b20320: Verifying Checksum\n",
      "246ae1b20320: Download complete\n",
      "e4ca327ec0e7: Verifying Checksum\n",
      "e4ca327ec0e7: Download complete\n",
      "1858d192a56c: Verifying Checksum\n",
      "1858d192a56c: Download complete\n",
      "d9fac7b97446: Verifying Checksum\n",
      "d9fac7b97446: Download complete\n",
      "e4ca327ec0e7: Pull complete\n",
      "953ce81694d3: Verifying Checksum\n",
      "953ce81694d3: Download complete\n",
      "c34d068d8571: Verifying Checksum\n",
      "c34d068d8571: Download complete\n",
      "07a6a041312d: Verifying Checksum\n",
      "07a6a041312d: Download complete\n",
      "6efc8cdc3722: Verifying Checksum\n",
      "6efc8cdc3722: Download complete\n",
      "78fc2e423513: Verifying Checksum\n",
      "78fc2e423513: Download complete\n",
      "3b911466f23c: Download complete\n",
      "88b8cc84069a: Verifying Checksum\n",
      "88b8cc84069a: Download complete\n",
      "3b911466f23c: Pull complete\n",
      "88617b1e05df: Pull complete\n",
      "d8988db501a0: Pull complete\n",
      "246ae1b20320: Pull complete\n",
      "1858d192a56c: Pull complete\n",
      "88b8cc84069a: Pull complete\n",
      "d9fac7b97446: Pull complete\n",
      "953ce81694d3: Pull complete\n",
      "c34d068d8571: Pull complete\n",
      "07a6a041312d: Pull complete\n",
      "6efc8cdc3722: Pull complete\n",
      "78fc2e423513: Pull complete\n",
      "Digest: sha256:ba5b4c25fb452589d9cbe052329ef3c1eb41eaac6877f4d56508ed7426b8a4a4\n",
      "Status: Downloaded newer image for 763104351884.dkr.ecr.ap-southeast-1.amazonaws.com/autogluon-training:0.3.1-cpu-py37-ubuntu18.04\n",
      " ---> 05a598fd360c\n",
      "Step 3/9 : RUN pip install -U pip\n",
      " ---> Running in 5a8960b27c7a\n",
      "Requirement already satisfied: pip in /usr/local/lib/python3.7/site-packages (21.2.4)\n",
      "Collecting pip\n",
      "  Downloading pip-22.3.1-py3-none-any.whl (2.1 MB)\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 21.2.4\n",
      "    Uninstalling pip-21.2.4:\n",
      "      Successfully uninstalled pip-21.2.4\n",
      "Successfully installed pip-22.3.1\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mRemoving intermediate container 5a8960b27c7a\n",
      " ---> cd0b55c5237f\n",
      "Step 4/9 : RUN pip install bokeh==2.0.1\n",
      " ---> Running in d1873f5076b8\n",
      "Collecting bokeh==2.0.1\n",
      "  Downloading bokeh-2.0.1.tar.gz (8.6 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.6/8.6 MB 4.1 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.7/site-packages (from bokeh==2.0.1) (5.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/site-packages (from bokeh==2.0.1) (2.8.2)\n",
      "Requirement already satisfied: Jinja2>=2.7 in /usr/local/lib/python3.7/site-packages (from bokeh==2.0.1) (3.0.1)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/site-packages (from bokeh==2.0.1) (1.21.2)\n",
      "Requirement already satisfied: pillow>=4.0 in /usr/local/lib/python3.7/site-packages (from bokeh==2.0.1) (8.3.2)\n",
      "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.7/site-packages (from bokeh==2.0.1) (21.0)\n",
      "Requirement already satisfied: tornado>=5 in /usr/local/lib/python3.7/site-packages (from bokeh==2.0.1) (6.1)\n",
      "Requirement already satisfied: typing_extensions>=3.7.4 in /usr/local/lib/python3.7/site-packages (from bokeh==2.0.1) (3.10.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.7/site-packages (from Jinja2>=2.7->bokeh==2.0.1) (2.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/site-packages (from packaging>=16.8->bokeh==2.0.1) (2.4.7)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.1->bokeh==2.0.1) (1.16.0)\n",
      "Building wheels for collected packages: bokeh\n",
      "  Building wheel for bokeh (setup.py): started\n",
      "  Building wheel for bokeh (setup.py): finished with status 'done'\n",
      "  Created wheel for bokeh: filename=bokeh-2.0.1-py3-none-any.whl size=9080039 sha256=0de8782fe328dd83fc57915f6887a764bced0965e2767a39e980f52f0e7686fa\n",
      "  Stored in directory: /root/.cache/pip/wheels/d8/44/db/647eeda59a5480a60049f7a3668c69ce252f8c0c7fc93c2559\n",
      "Successfully built bokeh\n",
      "Installing collected packages: bokeh\n",
      "Successfully installed bokeh-2.0.1\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mRemoving intermediate container d1873f5076b8\n",
      " ---> 5a91f1ff2c37\n",
      "Step 5/9 : RUN mkdir -p /opt/program\n",
      " ---> Running in 11640948ad34\n",
      "Removing intermediate container 11640948ad34\n",
      " ---> bfcbf1f50916\n",
      "Step 6/9 : RUN mkdir -p /opt/ml\n",
      " ---> Running in 70286e51bce4\n",
      "Removing intermediate container 70286e51bce4\n",
      " ---> 027683bf280a\n",
      "Step 7/9 : COPY train.py /opt/program\n",
      " ---> eadb72cf2a9f\n",
      "Step 8/9 : WORKDIR /opt/program\n",
      " ---> Running in cc38a3fa5008\n",
      "Removing intermediate container cc38a3fa5008\n",
      " ---> 2b580f6d176d\n",
      "Step 9/9 : ENTRYPOINT [\"python\", \"train.py\"]\n",
      " ---> Running in b420a33ef644\n",
      "Removing intermediate container b420a33ef644\n",
      " ---> 629f7cb78eb7\n",
      "Successfully built 629f7cb78eb7\n",
      "Successfully tagged sagemaker-studio-d-h0kay08tqcv4:herley\n",
      "\n",
      "[Container] 2023/01/08 06:33:54 Running command docker tag $IMAGE_REPO_NAME:$IMAGE_TAG $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG\n",
      "\n",
      "[Container] 2023/01/08 06:33:54 Phase complete: BUILD State: SUCCEEDED\n",
      "[Container] 2023/01/08 06:33:54 Phase context status code:  Message:\n",
      "[Container] 2023/01/08 06:33:54 Entering phase POST_BUILD\n",
      "[Container] 2023/01/08 06:33:54 Running command echo Build completed on `date`\n",
      "Build completed on Sun Jan 8 06:33:54 UTC 2023\n",
      "\n",
      "[Container] 2023/01/08 06:33:54 Running command echo Pushing the Docker image...\n",
      "Pushing the Docker image...\n",
      "\n",
      "[Container] 2023/01/08 06:33:54 Running command docker push $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG\n",
      "The push refers to repository [623127157773.dkr.ecr.ap-southeast-1.amazonaws.com/sagemaker-studio-d-h0kay08tqcv4]\n",
      "84009d5a7309: Preparing\n",
      "f7d2fa292785: Preparing\n",
      "e992665a8474: Preparing\n",
      "dc10c67dd165: Preparing\n",
      "74f89d27fb38: Preparing\n",
      "7d525756722c: Preparing\n",
      "14f4ab21e4db: Preparing\n",
      "0a0c73abef06: Preparing\n",
      "fb34e4d79698: Preparing\n",
      "abcc261e8da4: Preparing\n",
      "41036ba4fa86: Preparing\n",
      "9fa63e417143: Preparing\n",
      "bb0270201345: Preparing\n",
      "9c1280593405: Preparing\n",
      "b29f90e0a023: Preparing\n",
      "fe49db333c91: Preparing\n",
      "d0f308df6b39: Preparing\n",
      "6babb56be259: Preparing\n",
      "7d525756722c: Waiting\n",
      "14f4ab21e4db: Waiting\n",
      "0a0c73abef06: Waiting\n",
      "fb34e4d79698: Waiting\n",
      "abcc261e8da4: Waiting\n",
      "41036ba4fa86: Waiting\n",
      "9fa63e417143: Waiting\n",
      "bb0270201345: Waiting\n",
      "9c1280593405: Waiting\n",
      "b29f90e0a023: Waiting\n",
      "fe49db333c91: Waiting\n",
      "d0f308df6b39: Waiting\n",
      "6babb56be259: Waiting\n",
      "f7d2fa292785: Pushed\n",
      "e992665a8474: Pushed\n",
      "84009d5a7309: Pushed\n",
      "74f89d27fb38: Pushed\n",
      "7d525756722c: Pushed\n",
      "0a0c73abef06: Pushed\n",
      "14f4ab21e4db: Pushed\n",
      "fb34e4d79698: Pushed\n",
      "abcc261e8da4: Pushed\n",
      "dc10c67dd165: Pushed\n",
      "9c1280593405: Pushed\n",
      "b29f90e0a023: Pushed\n",
      "41036ba4fa86: Pushed\n",
      "fe49db333c91: Pushed\n",
      "6babb56be259: Pushed\n",
      "bb0270201345: Pushed\n",
      "d0f308df6b39: Pushed\n",
      "9fa63e417143: Pushed\n",
      "herley: digest: sha256:f32448c2e5e4d7eb3d640484ee1b412e13ef202fbae5f3c969bc10718fb5a613 size: 4095\n",
      "\n",
      "[Container] 2023/01/08 06:36:29 Phase complete: POST_BUILD State: SUCCEEDED\n",
      "[Container] 2023/01/08 06:36:29 Phase context status code:  Message:\n",
      "\n",
      "Image URI: 623127157773.dkr.ecr.ap-southeast-1.amazonaws.com/sagemaker-studio-d-h0kay08tqcv4:herley\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "aws_region = sagemaker.Session().boto_session.region_name\n",
    "!sm-docker build --build-arg REGION={aws_region} ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "column_names = [\"sex\", \"length\", \"diameter\", \"height\", \"whole_weight\", \"shucked_weight\", \"viscera_weight\", \"shell_weight\", \"rings\"]\n",
    "abalone_data = pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data\", names=column_names)\n",
    "training_data, testing_data = train_test_split(abalone_data, test_size=0.1)\n",
    "training_data.to_csv(\"training.csv\")\n",
    "testing_data.to_csv(\"testing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import datetime\n",
    "\n",
    "image_uri = \"623127157773.dkr.ecr.ap-southeast-1.amazonaws.com/sagemaker-studio-d-h0kay08tqcv4:herley\"\n",
    "role = sagemaker.get_execution_role()\n",
    "session = sagemaker.session.Session()\n",
    "bucket = session.default_bucket()\n",
    "job_version = datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S-%f')[:-3]\n",
    "job_name = f\"abalone-autogluon-{job_version}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "autogluon = Estimator(\n",
    "    image_uri=image_uri,\n",
    "    role=role,\n",
    "    output_path=f\"s3://{bucket}/{job_name}\",\n",
    "    base_job_name=job_name,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    hyperparameters={\n",
    "        \"label\": \"rings\",\n",
    "        \"bucket\": bucket,\n",
    "        \"training_job\": job_name\n",
    "    },\n",
    "    volume_size=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-08 06:52:26 Starting - Starting the training job...\n",
      "2023-01-08 06:52:40 Starting - Preparing the instances for trainingProfilerReport-1673160745: InProgress\n",
      "......\n",
      "2023-01-08 06:53:53 Downloading - Downloading input data...\n",
      "2023-01-08 06:54:25 Training - Training image download completed. Training in progress..\u001b[34mLoading Parameters\u001b[0m\n",
      "\u001b[34mTraining Models\u001b[0m\n",
      "\u001b[34mWarning: path already exists! This predictor may overwrite an existing predictor! path=\"/opt/ml/model\"\u001b[0m\n",
      "\u001b[34mBeginning AutoGluon training ...\u001b[0m\n",
      "\u001b[34mAutoGluon will save models to \"/opt/ml/model/\"\u001b[0m\n",
      "\u001b[34mAutoGluon Version:  0.3.1\u001b[0m\n",
      "\u001b[34mTrain Data Rows:    3759\u001b[0m\n",
      "\u001b[34mTrain Data Columns: 9\u001b[0m\n",
      "\u001b[34mPreprocessing data ...\u001b[0m\n",
      "\u001b[34mAutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\u001b[0m\n",
      "\u001b[34m#011First 10 (of 27) unique label values:  [9, 8, 7, 11, 12, 6, 19, 10, 14, 16]\u001b[0m\n",
      "\u001b[34m#011If 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\u001b[0m\n",
      "\u001b[34mWarning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 19 out of 27 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\u001b[0m\n",
      "\u001b[34mFraction of data from classes with at least 10 examples that will be kept for training models: 0.9938813514232508\u001b[0m\n",
      "\u001b[34mTrain Data Class Count: 19\u001b[0m\n",
      "\u001b[34mUsing Feature Generators to preprocess the data ...\u001b[0m\n",
      "\u001b[34mFitting AutoMLPipelineFeatureGenerator...\u001b[0m\n",
      "\u001b[34m#011Available Memory:                    15071.56 MB\u001b[0m\n",
      "\u001b[34m#011Train Data (Original)  Memory Usage: 0.46 MB (0.0% of available memory)\u001b[0m\n",
      "\u001b[34m#011Inferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\u001b[0m\n",
      "\u001b[34m#011Stage 1 Generators:\u001b[0m\n",
      "\u001b[34m#011#011Fitting AsTypeFeatureGenerator...\u001b[0m\n",
      "\u001b[34m#011Stage 2 Generators:\u001b[0m\n",
      "\u001b[34m#011#011Fitting FillNaFeatureGenerator...\u001b[0m\n",
      "\u001b[34m#011Stage 3 Generators:\u001b[0m\n",
      "\u001b[34m#011#011Fitting IdentityFeatureGenerator...\u001b[0m\n",
      "\u001b[34m#011#011Fitting CategoryFeatureGenerator...\u001b[0m\n",
      "\u001b[34m#011#011#011Fitting CategoryMemoryMinimizeFeatureGenerator...\u001b[0m\n",
      "\u001b[34m#011Stage 4 Generators:\u001b[0m\n",
      "\u001b[34m#011#011Fitting DropUniqueFeatureGenerator...\u001b[0m\n",
      "\u001b[34m#011Types of features in original data (raw dtype, special dtypes):\u001b[0m\n",
      "\u001b[34m#011#011('float', [])  : 7 | ['length', 'diameter', 'height', 'whole_weight', 'shucked_weight', ...]\u001b[0m\n",
      "\u001b[34m#011#011('int', [])    : 1 | ['Unnamed: 0']\u001b[0m\n",
      "\u001b[34m#011#011('object', []) : 1 | ['sex']\u001b[0m\n",
      "\u001b[34m#011Types of features in processed data (raw dtype, special dtypes):\u001b[0m\n",
      "\u001b[34m#011#011('category', []) : 1 | ['sex']\u001b[0m\n",
      "\u001b[34m#011#011('float', [])    : 7 | ['length', 'diameter', 'height', 'whole_weight', 'shucked_weight', ...]\u001b[0m\n",
      "\u001b[34m#011#011('int', [])      : 1 | ['Unnamed: 0']\u001b[0m\n",
      "\u001b[34m#0110.0s = Fit runtime\u001b[0m\n",
      "\u001b[34m#0119 features in original data used to generate 9 features in processed data.\u001b[0m\n",
      "\u001b[34m#011Train Data (Processed) Memory Usage: 0.24 MB (0.0% of available memory)\u001b[0m\n",
      "\u001b[34mData preprocessing and feature engineering runtime = 0.05s ...\u001b[0m\n",
      "\u001b[34mAutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\u001b[0m\n",
      "\u001b[34m#011To change this, specify the eval_metric argument of fit()\u001b[0m\n",
      "\u001b[34mAutomatically generating train/validation split with holdout_frac=0.13301409949454643, Train Rows: 3239, Val Rows: 497\u001b[0m\n",
      "\u001b[34mFitting 13 L1 models ...\u001b[0m\n",
      "\u001b[34mFitting model: KNeighborsUnif ...\u001b[0m\n",
      "\u001b[34m#0110.2656#011 = Validation score   (accuracy)\u001b[0m\n",
      "\u001b[34m#0110.01s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.1s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: KNeighborsDist ...\u001b[0m\n",
      "\u001b[34m#0110.2394#011 = Validation score   (accuracy)\u001b[0m\n",
      "\u001b[34m#0110.01s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.1s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: NeuralNetFastAI ...\u001b[0m\n",
      "\u001b[34mgenerated new fontManager\u001b[0m\n",
      "\u001b[34m#0110.3058#011 = Validation score   (accuracy)\u001b[0m\n",
      "\u001b[34m#0115.21s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.02s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: LightGBMXT ...\u001b[0m\n",
      "\u001b[34m#0110.2998#011 = Validation score   (accuracy)\u001b[0m\n",
      "\u001b[34m#0113.05s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.07s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: LightGBM ...\u001b[0m\n",
      "\u001b[34m#0110.2978#011 = Validation score   (accuracy)\u001b[0m\n",
      "\u001b[34m#0113.8s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.05s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: RandomForestGini ...\u001b[0m\n",
      "\u001b[34m#0110.2636#011 = Validation score   (accuracy)\u001b[0m\n",
      "\u001b[34m#0111.56s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.2s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: RandomForestEntr ...\u001b[0m\n",
      "\u001b[34m#0110.2716#011 = Validation score   (accuracy)\u001b[0m\n",
      "\u001b[34m#0112.85s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.2s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: CatBoost ...\u001b[0m\n",
      "\u001b[34m#0110.2757#011 = Validation score   (accuracy)\u001b[0m\n",
      "\u001b[34m#01111.78s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.01s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: ExtraTreesGini ...\u001b[0m\n",
      "\u001b[34m#0110.2596#011 = Validation score   (accuracy)\u001b[0m\n",
      "\u001b[34m#0111.05s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.21s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: ExtraTreesEntr ...\u001b[0m\n",
      "\u001b[34m#0110.2777#011 = Validation score   (accuracy)\u001b[0m\n",
      "\u001b[34m#0111.15s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.2s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: XGBoost ...\u001b[0m\n",
      "\u001b[34m#0110.2958#011 = Validation score   (accuracy)\u001b[0m\n",
      "\u001b[34m#0112.78s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.01s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: NeuralNetMXNet ...\u001b[0m\n",
      "\u001b[34m#0110.3099#011 = Validation score   (accuracy)\u001b[0m\n",
      "\u001b[34m#0118.18s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.02s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: LightGBMLarge ...\u001b[0m\n",
      "\u001b[34m#0110.2777#011 = Validation score   (accuracy)\u001b[0m\n",
      "\u001b[34m#01115.02s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.23s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: WeightedEnsemble_L2 ...\u001b[0m\n",
      "\u001b[34m#0110.33#011 = Validation score   (accuracy)\u001b[0m\n",
      "\u001b[34m#0110.52s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.0s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mAutoGluon training complete, total runtime = 64.57s ...\u001b[0m\n",
      "\u001b[34mTabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/opt/ml/model/\")\u001b[0m\n",
      "\u001b[34m*** Summary of fit() ***\u001b[0m\n",
      "\u001b[34mEstimated performance of each model:\n",
      "                  model  score_val  pred_time_val   fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\u001b[0m\n",
      "\u001b[34m0   WeightedEnsemble_L2   0.329980       0.417236  21.308125                0.000586           0.524212            2       True         14\u001b[0m\n",
      "\u001b[34m1        NeuralNetMXNet   0.309859       0.017277   8.179569                0.017277           8.179569            1       True         12\u001b[0m\n",
      "\u001b[34m2       NeuralNetFastAI   0.305835       0.019093   5.206276                0.019093           5.206276            1       True          3\u001b[0m\n",
      "\u001b[34m3            LightGBMXT   0.299799       0.065344   3.045308                0.065344           3.045308            1       True          4\u001b[0m\n",
      "\u001b[34m4              LightGBM   0.297787       0.053168   3.804168                0.053168           3.804168            1       True          5\u001b[0m\n",
      "\u001b[34m5               XGBoost   0.295775       0.006054   2.781394                0.006054           2.781394            1       True         11\u001b[0m\n",
      "\u001b[34m6        ExtraTreesEntr   0.277666       0.204660   1.147337                0.204660           1.147337            1       True         10\u001b[0m\n",
      "\u001b[34m7         LightGBMLarge   0.277666       0.231031  15.020855                0.231031          15.020855            1       True         13\u001b[0m\n",
      "\u001b[34m8              CatBoost   0.275654       0.007307  11.780352                0.007307          11.780352            1       True          8\u001b[0m\n",
      "\u001b[34m9      RandomForestEntr   0.271630       0.204605   2.850970                0.204605           2.850970            1       True          7\u001b[0m\n",
      "\u001b[34m10       KNeighborsUnif   0.265594       0.104106   0.008285                0.104106           0.008285            1       True          1\u001b[0m\n",
      "\u001b[34m11     RandomForestGini   0.263581       0.204775   1.563081                0.204775           1.563081            1       True          6\u001b[0m\n",
      "\u001b[34m12       ExtraTreesGini   0.259557       0.206648   1.048404                0.206648           1.048404            1       True          9\u001b[0m\n",
      "\u001b[34m13       KNeighborsDist   0.239437       0.103174   0.007828                0.103174           0.007828            1       True          2\u001b[0m\n",
      "\u001b[34mNumber of models trained: 14\u001b[0m\n",
      "\u001b[34mTypes of models trained:\u001b[0m\n",
      "\u001b[34m{'RFModel', 'XTModel', 'WeightedEnsembleModel', 'CatBoostModel', 'NNFastAiTabularModel', 'XGBoostModel', 'TabularNeuralNetModel', 'LGBModel', 'KNNModel'}\u001b[0m\n",
      "\u001b[34mBagging used: False \u001b[0m\n",
      "\u001b[34mMulti-layer stack-ensembling used: False \u001b[0m\n",
      "\u001b[34mFeature Metadata (Processed):\u001b[0m\n",
      "\u001b[34m(raw dtype, special dtypes):\u001b[0m\n",
      "\u001b[34m('category', []) : 1 | ['sex']\u001b[0m\n",
      "\u001b[34m('float', [])    : 7 | ['length', 'diameter', 'height', 'whole_weight', 'shucked_weight', ...]\u001b[0m\n",
      "\u001b[34m('int', [])      : 1 | ['Unnamed: 0']\u001b[0m\n",
      "\u001b[34mPlot summary of models saved to file: /opt/ml/model/SummaryOfModels.html\u001b[0m\n",
      "\u001b[34m*** End of fit() summary ***\u001b[0m\n",
      "\u001b[34mTestig Models\u001b[0m\n",
      "\u001b[34mLoaded data from: /opt/ml/input/data/testing/testing.csv | Columns = 10 / 10 | Rows = 418 -> 418\u001b[0m\n",
      "\u001b[34mEvaluation: accuracy on test data: 0.2942583732057416\u001b[0m\n",
      "\u001b[34mEvaluations on test data:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"accuracy\": 0.2942583732057416,\n",
      "    \"balanced_accuracy\": 0.14759349591595244,\n",
      "    \"mcc\": 0.20056068976685734\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mAutoGluon Job Complete\u001b[0m\n",
      "\n",
      "2023-01-08 06:55:46 Uploading - Uploading generated training model\n",
      "2023-01-08 06:56:28 Completed - Training job completed\n",
      "Training seconds: 152\n",
      "Billable seconds: 152\n"
     ]
    }
   ],
   "source": [
    "autogluon.fit(\n",
    "    inputs={\n",
    "        \"training\": session.upload_data(\n",
    "            \"training.csv\",\n",
    "            bucket=bucket,\n",
    "            key_prefix=f\"{job_name}/input\"\n",
    "        ),\n",
    "        \"testing\": session.upload_data(\n",
    "            \"testing.csv\",\n",
    "            bucket=bucket,\n",
    "            key_prefix=f\"{job_name}/input\"\n",
    "        )\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir extract\n",
    "sagemaker.s3.S3Downloader.download(autogluon.model_data, \"./\")\n",
    "!tar xfz ./model.tar.gz -C extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.294258</td>\n",
       "      <td>0.329980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NeuralNetMXNet</td>\n",
       "      <td>0.282297</td>\n",
       "      <td>0.309859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.305835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.299799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.255981</td>\n",
       "      <td>0.297787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.255981</td>\n",
       "      <td>0.295775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>0.258373</td>\n",
       "      <td>0.277666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ExtraTreesEntr</td>\n",
       "      <td>0.248804</td>\n",
       "      <td>0.277666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.265550</td>\n",
       "      <td>0.275654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RandomForestEntr</td>\n",
       "      <td>0.241627</td>\n",
       "      <td>0.271630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>0.244019</td>\n",
       "      <td>0.265594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RandomForestGini</td>\n",
       "      <td>0.234450</td>\n",
       "      <td>0.263581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ExtraTreesGini</td>\n",
       "      <td>0.241627</td>\n",
       "      <td>0.259557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>0.265550</td>\n",
       "      <td>0.239437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  score_test  score_val\n",
       "0   WeightedEnsemble_L2    0.294258   0.329980\n",
       "1        NeuralNetMXNet    0.282297   0.309859\n",
       "2       NeuralNetFastAI    0.272727   0.305835\n",
       "3            LightGBMXT    0.263158   0.299799\n",
       "4              LightGBM    0.255981   0.297787\n",
       "5               XGBoost    0.255981   0.295775\n",
       "6         LightGBMLarge    0.258373   0.277666\n",
       "7        ExtraTreesEntr    0.248804   0.277666\n",
       "8              CatBoost    0.265550   0.275654\n",
       "9      RandomForestEntr    0.241627   0.271630\n",
       "10       KNeighborsUnif    0.244019   0.265594\n",
       "11     RandomForestGini    0.234450   0.263581\n",
       "12       ExtraTreesGini    0.241627   0.259557\n",
       "13       KNeighborsDist    0.265550   0.239437"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./extract/Leaderboard.csv\")\n",
    "df = df.filter([\"model\",\"score_test\", \"score_val\"]).sort_values(by=\"score_val\", ascending=False).reset_index().drop(columns=\"index\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "<!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "  \n",
       "  <head>\n",
       "    \n",
       "      <meta charset=\"utf-8\">\n",
       "      <title>Models produced during fit()</title>\n",
       "      \n",
       "      \n",
       "        \n",
       "          \n",
       "        \n",
       "        \n",
       "          \n",
       "        <script type=\"text/javascript\" src=\"https://cdn.bokeh.org/bokeh/release/bokeh-2.0.1.min.js\" integrity=\"sha384-JpP8FXbgAZLkfur7LiK3j9AGBhHNIvF742meBJrjO2ShJDhCG2I1uVvW+0DUtrmc\" crossorigin=\"anonymous\"></script>\n",
       "        <script type=\"text/javascript\">\n",
       "            Bokeh.set_log_level(\"info\");\n",
       "        </script>\n",
       "        \n",
       "      \n",
       "      \n",
       "    \n",
       "  </head>\n",
       "  \n",
       "  \n",
       "  <body>\n",
       "    \n",
       "      \n",
       "        \n",
       "          \n",
       "          \n",
       "            \n",
       "              <div class=\"bk-root\" id=\"d84f94ce-3df7-4d81-a9a6-8dc614602ca5\" data-root-id=\"1003\"></div>\n",
       "            \n",
       "          \n",
       "        \n",
       "      \n",
       "      \n",
       "        <script type=\"application/json\" id=\"1157\">\n",
       "          {\"b7d0a242-9fd4-4290-86c5-6b19d6f49bc9\":{\"roots\":{\"references\":[{\"attributes\":{\"index\":0,\"label\":{\"value\":\"KNNModel\"},\"renderers\":[{\"id\":\"1041\"}]},\"id\":\"1059\",\"type\":\"LegendItem\"},{\"attributes\":{},\"id\":\"1019\",\"type\":\"BasicTicker\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":0.5,\"fill_color\":\"lightgrey\",\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":1.0,\"line_color\":\"black\",\"line_dash\":[4,4],\"line_width\":2,\"render_mode\":\"css\",\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"1029\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"index\":13,\"label\":{\"value\":\"WeightedEnsembleModel\"},\"renderers\":[{\"id\":\"1041\"}]},\"id\":\"1053\",\"type\":\"LegendItem\"},{\"attributes\":{\"index\":10,\"label\":{\"value\":\"XGBoostModel\"},\"renderers\":[{\"id\":\"1041\"}]},\"id\":\"1056\",\"type\":\"LegendItem\"},{\"attributes\":{\"data\":{\"hyperparameters\":[\"weights: uniform&lt;br&gt;n_jobs: -1\",\"weights: distance&lt;br&gt;n_jobs: -1\",\"layers: None&lt;br&gt;emb_drop: 0.1&lt;br&gt;ps: 0.1&lt;br&gt;bs: 256&lt;br&gt;lr: 0.01&lt;br&gt;epochs: 30&lt;br&gt;early.stopping.min_delta: 0.0001&lt;br&gt;early.stopping.patience: 20&lt;br&gt;smoothing: 0.0\",\"num_boost_round: 10000&lt;br&gt;num_threads: -1&lt;br&gt;learning_rate: 0.05&lt;br&gt;objective: multiclass&lt;br&gt;verbose: -1&lt;br&gt;boosting_type: gbdt&lt;br&gt;two_round: True&lt;br&gt;extra_trees: True\",\"num_boost_round: 10000&lt;br&gt;num_threads: -1&lt;br&gt;learning_rate: 0.05&lt;br&gt;objective: multiclass&lt;br&gt;verbose: -1&lt;br&gt;boosting_type: gbdt&lt;br&gt;two_round: True\",\"n_estimators: 300&lt;br&gt;n_jobs: -1&lt;br&gt;random_state: 0&lt;br&gt;bootstrap: True&lt;br&gt;criterion: gini\",\"n_estimators: 300&lt;br&gt;n_jobs: -1&lt;br&gt;random_state: 0&lt;br&gt;bootstrap: True&lt;br&gt;criterion: entropy\",\"iterations: 10000&lt;br&gt;learning_rate: 0.05&lt;br&gt;random_seed: 0&lt;br&gt;allow_writing_files: False&lt;br&gt;eval_metric: Accuracy\",\"n_estimators: 300&lt;br&gt;n_jobs: -1&lt;br&gt;random_state: 0&lt;br&gt;bootstrap: True&lt;br&gt;criterion: gini\",\"n_estimators: 300&lt;br&gt;n_jobs: -1&lt;br&gt;random_state: 0&lt;br&gt;bootstrap: True&lt;br&gt;criterion: entropy\",\"n_estimators: 10000&lt;br&gt;learning_rate: 0.1&lt;br&gt;n_jobs: -1&lt;br&gt;proc.max_category_levels: 100&lt;br&gt;objective: multi:softmax&lt;br&gt;booster: gbtree&lt;br&gt;num_class: 19&lt;br&gt;use_label_encoder: False\",\"num_epochs: 500&lt;br&gt;epochs_wo_improve: 20&lt;br&gt;seed_value: None&lt;br&gt;proc.embed_min_categories: 4&lt;br&gt;proc.impute_strategy: median&lt;br&gt;proc.max_category_levels: 100&lt;br&gt;proc.skew_threshold: 0.99&lt;br&gt;network_type: widedeep&lt;br&gt;layers: None&lt;br&gt;numeric_embed_dim: None&lt;br&gt;activation: relu&lt;br&gt;max_layer_width: 2056&lt;br&gt;embedding_size_factor: 1.0&lt;br&gt;embed_exponent: 0.56&lt;br&gt;max_embedding_dim: 100&lt;br&gt;y_range: None&lt;br&gt;y_range_extend: 0.05&lt;br&gt;use_batchnorm: True&lt;br&gt;dropout_prob: 0.1&lt;br&gt;batch_size: 512&lt;br&gt;loss_function: None&lt;br&gt;optimizer: adam&lt;br&gt;learning_rate: 0.0003&lt;br&gt;weight_decay: 1e-06&lt;br&gt;clip_gradient: 100.0&lt;br&gt;momentum: 0.9&lt;br&gt;lr_scheduler: None&lt;br&gt;base_lr: 3e-05&lt;br&gt;target_lr: 1.0&lt;br&gt;lr_decay: 0.1&lt;br&gt;warmup_epochs: 10&lt;br&gt;use_ngram_features: False\",\"num_boost_round: 10000&lt;br&gt;num_threads: -1&lt;br&gt;learning_rate: 0.03&lt;br&gt;objective: multiclass&lt;br&gt;verbose: -1&lt;br&gt;boosting_type: gbdt&lt;br&gt;two_round: True&lt;br&gt;num_leaves: 128&lt;br&gt;feature_fraction: 0.9&lt;br&gt;min_data_in_leaf: 3\",\"use_orig_features: False&lt;br&gt;max_base_models: 25&lt;br&gt;max_base_models_per_type: 5&lt;br&gt;save_bag_folds: True\"],\"inference_latency\":[0.10410618782043457,0.10317444801330566,0.019093036651611328,0.06534385681152344,0.05316781997680664,0.20477509498596191,0.2046051025390625,0.0073070526123046875,0.20664763450622559,0.20465993881225586,0.0060541629791259766,0.017277002334594727,0.23103070259094238,0.4172356128692627],\"model\":[\"KNeighborsUnif\",\"KNeighborsDist\",\"NeuralNetFastAI\",\"LightGBMXT\",\"LightGBM\",\"RandomForestGini\",\"RandomForestEntr\",\"CatBoost\",\"ExtraTreesGini\",\"ExtraTreesEntr\",\"XGBoost\",\"NeuralNetMXNet\",\"LightGBMLarge\",\"WeightedEnsemble_L2\"],\"model_type\":[\"KNNModel\",\"KNNModel\",\"NNFastAiTabularModel\",\"LGBModel\",\"LGBModel\",\"RFModel\",\"RFModel\",\"CatBoostModel\",\"XTModel\",\"XTModel\",\"XGBoostModel\",\"TabularNeuralNetModel\",\"LGBModel\",\"WeightedEnsembleModel\"],\"performance\":[0.2655935613682093,0.23943661971830985,0.3058350100603622,0.29979879275653926,0.2977867203219316,0.2635814889336016,0.2716297786720322,0.27565392354124746,0.2595573440643863,0.2776659959758551,0.29577464788732394,0.30985915492957744,0.2776659959758551,0.3299798792756539],\"training_time\":[0.008285045623779297,0.007827520370483398,5.206275701522827,3.0453078746795654,3.8041677474975586,1.5630812644958496,2.8509702682495117,11.780352354049683,1.0484042167663574,1.147336721420288,2.7813944816589355,8.179569005966187,15.020854711532593,21.308125495910645]},\"selected\":{\"id\":\"1048\"},\"selection_policy\":{\"id\":\"1049\"}},\"id\":\"1002\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"index\":11,\"label\":{\"value\":\"TabularNeuralNetModel\"},\"renderers\":[{\"id\":\"1041\"}]},\"id\":\"1057\",\"type\":\"LegendItem\"},{\"attributes\":{\"factors\":[\"RFModel\",\"XTModel\",\"WeightedEnsembleModel\",\"CatBoostModel\",\"NNFastAiTabularModel\",\"XGBoostModel\",\"TabularNeuralNetModel\",\"LGBModel\",\"KNNModel\"],\"palette\":[\"#1f77b4\",\"#ff7f0e\",\"#2ca02c\",\"#d62728\",\"#9467bd\",\"#8c564b\",\"#e377c2\",\"#7f7f7f\",\"#bcbd22\"]},\"id\":\"1001\",\"type\":\"CategoricalColorMapper\"},{\"attributes\":{\"index\":3,\"label\":{\"value\":\"LGBModel\"},\"renderers\":[{\"id\":\"1041\"}]},\"id\":\"1058\",\"type\":\"LegendItem\"},{\"attributes\":{\"below\":[{\"id\":\"1014\"}],\"center\":[{\"id\":\"1017\"},{\"id\":\"1021\"}],\"left\":[{\"id\":\"1018\"}],\"renderers\":[{\"id\":\"1041\"}],\"right\":[{\"id\":\"1060\"}],\"title\":{\"id\":\"1004\"},\"toolbar\":{\"id\":\"1030\"},\"x_range\":{\"id\":\"1006\"},\"x_scale\":{\"id\":\"1010\"},\"y_range\":{\"id\":\"1008\"},\"y_scale\":{\"id\":\"1012\"}},\"id\":\"1003\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"axis\":{\"id\":\"1018\"},\"dimension\":1,\"ticker\":null},\"id\":\"1021\",\"type\":\"Grid\"},{\"attributes\":{\"items\":[{\"id\":\"1051\"},{\"id\":\"1052\"},{\"id\":\"1053\"},{\"id\":\"1054\"},{\"id\":\"1055\"},{\"id\":\"1056\"},{\"id\":\"1057\"},{\"id\":\"1058\"},{\"id\":\"1059\"}],\"location\":[0,0]},\"id\":\"1060\",\"type\":\"Legend\"},{\"attributes\":{\"index\":5,\"label\":{\"value\":\"RFModel\"},\"renderers\":[{\"id\":\"1041\"}]},\"id\":\"1051\",\"type\":\"LegendItem\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"field\":\"model_type\",\"transform\":{\"id\":\"1001\"}},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"field\":\"model_type\",\"transform\":{\"id\":\"1001\"}},\"size\":{\"units\":\"screen\",\"value\":20},\"x\":{\"field\":\"inference_latency\"},\"y\":{\"field\":\"performance\"}},\"id\":\"1040\",\"type\":\"Circle\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1022\"},{\"id\":\"1023\"},{\"id\":\"1024\"},{\"id\":\"1025\"},{\"id\":\"1026\"},{\"id\":\"1027\"},{\"id\":\"1028\"}]},\"id\":\"1030\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"1022\",\"type\":\"CrosshairTool\"},{\"attributes\":{},\"id\":\"1048\",\"type\":\"Selection\"},{\"attributes\":{\"index\":2,\"label\":{\"value\":\"NNFastAiTabularModel\"},\"renderers\":[{\"id\":\"1041\"}]},\"id\":\"1055\",\"type\":\"LegendItem\"},{\"attributes\":{\"source\":{\"id\":\"1002\"}},\"id\":\"1042\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"1023\",\"type\":\"PanTool\"},{\"attributes\":{},\"id\":\"1006\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1010\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1015\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1047\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1024\",\"type\":\"WheelZoomTool\"},{\"attributes\":{},\"id\":\"1045\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"callback\":null,\"tooltips\":[[\"performance\",\"@performance{safe}\"],[\"model\",\"@model{safe}\"],[\"model_type\",\"@model_type{safe}\"],[\"hyperparameters\",\"@hyperparameters{safe}\"],[\"inference_latency\",\"@inference_latency{safe}\"],[\"training_time\",\"@training_time{safe}\"]]},\"id\":\"1027\",\"type\":\"HoverTool\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.5},\"fill_color\":{\"field\":\"model_type\",\"transform\":{\"id\":\"1001\"}},\"line_alpha\":{\"value\":0.5},\"line_color\":{\"field\":\"model_type\",\"transform\":{\"id\":\"1001\"}},\"size\":{\"units\":\"screen\",\"value\":20},\"x\":{\"field\":\"inference_latency\"},\"y\":{\"field\":\"performance\"}},\"id\":\"1039\",\"type\":\"Circle\"},{\"attributes\":{\"overlay\":{\"id\":\"1029\"}},\"id\":\"1025\",\"type\":\"BoxZoomTool\"},{\"attributes\":{},\"id\":\"1049\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"text\":\"Models produced during fit()\"},\"id\":\"1004\",\"type\":\"Title\"},{\"attributes\":{},\"id\":\"1026\",\"type\":\"ResetTool\"},{\"attributes\":{\"index\":8,\"label\":{\"value\":\"XTModel\"},\"renderers\":[{\"id\":\"1041\"}]},\"id\":\"1052\",\"type\":\"LegendItem\"},{\"attributes\":{},\"id\":\"1012\",\"type\":\"LinearScale\"},{\"attributes\":{\"data_source\":{\"id\":\"1002\"},\"glyph\":{\"id\":\"1039\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1040\"},\"selection_glyph\":null,\"view\":{\"id\":\"1042\"}},\"id\":\"1041\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"axis_label\":\"performance\",\"formatter\":{\"id\":\"1045\"},\"ticker\":{\"id\":\"1019\"}},\"id\":\"1018\",\"type\":\"LinearAxis\"},{\"attributes\":{\"axis\":{\"id\":\"1014\"},\"ticker\":null},\"id\":\"1017\",\"type\":\"Grid\"},{\"attributes\":{\"index\":7,\"label\":{\"value\":\"CatBoostModel\"},\"renderers\":[{\"id\":\"1041\"}]},\"id\":\"1054\",\"type\":\"LegendItem\"},{\"attributes\":{},\"id\":\"1028\",\"type\":\"SaveTool\"},{\"attributes\":{\"axis_label\":\"inference_latency\",\"formatter\":{\"id\":\"1047\"},\"ticker\":{\"id\":\"1015\"}},\"id\":\"1014\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1008\",\"type\":\"DataRange1d\"}],\"root_ids\":[\"1003\"]},\"title\":\"Bokeh Application\",\"version\":\"2.0.1\"}}\n",
       "        </script>\n",
       "        <script type=\"text/javascript\">\n",
       "          (function() {\n",
       "            var fn = function() {\n",
       "              Bokeh.safely(function() {\n",
       "                (function(root) {\n",
       "                  function embed_document(root) {\n",
       "                    \n",
       "                  var docs_json = document.getElementById('1157').textContent;\n",
       "                  var render_items = [{\"docid\":\"b7d0a242-9fd4-4290-86c5-6b19d6f49bc9\",\"root_ids\":[\"1003\"],\"roots\":{\"1003\":\"d84f94ce-3df7-4d81-a9a6-8dc614602ca5\"}}];\n",
       "                  root.Bokeh.embed.embed_items(docs_json, render_items);\n",
       "                \n",
       "                  }\n",
       "                  if (root.Bokeh !== undefined) {\n",
       "                    embed_document(root);\n",
       "                  } else {\n",
       "                    var attempts = 0;\n",
       "                    var timer = setInterval(function(root) {\n",
       "                      if (root.Bokeh !== undefined) {\n",
       "                        clearInterval(timer);\n",
       "                        embed_document(root);\n",
       "                      } else {\n",
       "                        attempts++;\n",
       "                        if (attempts > 100) {\n",
       "                          clearInterval(timer);\n",
       "                          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "                        }\n",
       "                      }\n",
       "                    }, 10, root)\n",
       "                  }\n",
       "                })(window);\n",
       "              });\n",
       "            };\n",
       "            if (document.readyState != \"loading\") fn();\n",
       "            else document.addEventListener(\"DOMContentLoaded\", fn);\n",
       "          })();\n",
       "        </script>\n",
       "    \n",
       "  </body>\n",
       "  \n",
       "</html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "IPython.display.HTML(filename=\"./extract/SummaryOfModels.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7 (tags/v3.10.7:6cc6b13, Sep  5 2022, 14:08:36) [MSC v.1933 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
